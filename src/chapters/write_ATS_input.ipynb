{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3059ae87-5f5c-409c-b216-167261f1dca1",
   "metadata": {},
   "source": [
    "# Write ATS input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee695604-3f49-44a7-abcf-a5486382dd50",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We now generate three input files -- two for spinup (steadystate solution and cyclic steadystate solution) and one for transient runs.\n",
    "\n",
    "Steadystate has its own physics, but cyclic steadystate and transient share a common set of physics.  Each have their own met data strategy.\n",
    "\n",
    "The first step is to generate the sections of xml that will replace parts of the template files.  This is done prior to loading any templates to make clear that these are totally generated from scratch using the ats_input_spec tool.\n",
    "\n",
    "Note that throughout, we will assume an additional level of folder nesting, e.g. runs will be completed in '../spinup-CoalCreek/run0', meaning that we have to append an extra '../' to the start of all filenames.  This makes it easier to deal with mistakes, continued runs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06330b40-3a79-46ee-9e9e-2e497062831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36fe3039-0e9f-46d7-aadb-9b412458bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml, pickle\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s: %(message)s')\n",
    "\n",
    "# ats_input_spec library, to be moved to amanzi_xml\n",
    "import ats_input_spec\n",
    "import ats_input_spec.public\n",
    "import ats_input_spec.io\n",
    "\n",
    "# amanzi_xml, included in AMANZI_SRC_DIR/tools/amanzi_xml\n",
    "import amanzi_xml.utils.io as aio\n",
    "import amanzi_xml.utils.search as asearch\n",
    "import amanzi_xml.utils.errors as aerrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ccaf4ce-aea4-4c76-8ada-dad467aac24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NeversinkHeadwaters_11Catchments_cluster' # name the domain, used in filenames, etc\n",
    "canopy = True\n",
    "data_dir = \"../data/\"\n",
    "input_dir = \"../model/inputs/\"\n",
    "# mesh_dir = \"../../data/meshes\"\n",
    "\n",
    "template_dir =input_dir + f\"template_xml/master/ecohydro/\"\n",
    "out_dir = \"../data/WW_output/\"\n",
    "pickle_dir = out_dir + \"pickle/\"\n",
    "processed_dir = data_dir + \"processed/\"\n",
    "\n",
    "# case = 'cyber'\n",
    "# if canopy:\n",
    "#     template_filename = template_dir + f\"reactive-canopy-{case}-template.xml\"\n",
    "# else:\n",
    "#     template_filename = template_dir + f\"reactive-{case}-template.xml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7744cf6f-fe69-4455-a187-5adc8a3ebf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daymet_filename': '../data/processed/NeversinkHeadwaters_11Catchments_DayMet_1980_2020-UTM.h5',\n",
       " 'daymet_spinup_filename': '../data/processed/NeversinkHeadwaters_11Catchments_DayMet_typical_1980_2020-UTM.h5',\n",
       " 'mesh_filename': '../data/meshes/NeversinkHeadwaters_11Catchments-clustered.exo',\n",
       " 'subsurface_properties_filename': '../data/WW_output/NeversinkHeadwaters_11Catchments_subsurface_properties-clustered.csv'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(out_dir + f\"{name}_config.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7f20bd3-022a-4054-b21b-9cfcd1988f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary of outputs -- will include all filenames generated\n",
    "# config = {}\n",
    "\n",
    "# name = \"NeversinkHeadwaters\"\n",
    "# input xmls\n",
    "mesh_filename = os.path.join('../..', config['mesh_filename'])\n",
    "\n",
    "# config['subsurface_properties_filename'] = data_dir + \"WW_output/subsurface_prop.csv\"\n",
    "# input data\n",
    "config['modis_typical_filename'] = processed_dir + f'NeversinkHeadwaters_MODIS_LAI_typical_1980_2020.h5'\n",
    "config['daymet_filename'] = processed_dir + f'NeversinkHeadwaters_Daymet_1980_2020-UTM.h5'\n",
    "config['daymet_spinup_filename'] = processed_dir + f'NeversinkHeadwaters_DayMet_typical_1980_2020-UTM.h5'\n",
    "# run dirs\n",
    "config[f'spinup_steadystate_{name}_rundir'] = f'../model/{name}_spinup_steadystate'\n",
    "config[f'spinup_cyclic_{name}_rundir'] = f'../model/{name}_spinup_cyclic'\n",
    "config[f'transient_{name}_rundir'] = f'../model/{name}_transient'\n",
    "\n",
    "config[f'spinup_steadystate_{name}_template'] = template_dir + f'spinup_steadystate-template.xml'\n",
    "config[f'spinup_cyclic_{name}_template'] = template_dir + f'spinup_cyclic-template.xml'\n",
    "config[f'transient_{name}_template'] = template_dir + f'transient-template.xml'\n",
    "\n",
    "config['generated_ats'] = input_dir + f'{name}_generated_ats.xml'\n",
    "config[f'spinup_steadystate_{name}_filename'] = input_dir + f'{name}_spinup_steadystate.xml'\n",
    "config[f'spinup_cyclic_{name}_filename'] = input_dir + f'{name}_spinup_cyclic.xml'\n",
    "config[f'transient_{name}_filename'] = input_dir + f'{name}_transient.xml'\n",
    "# if canopy:\n",
    "#     config[f'spinup_cyclic_{name}_filename'] = input_dir + f'{name}_spinup_cyclic-reactive-canopy-{case}.xml'\n",
    "#     config[f'transient_{name}_filename'] = input_dir + f'{name}_transient-reactive-canopy-{case}.xml'    \n",
    "# else:\n",
    "#     config[f'spinup_cyclic_{name}_filename'] = input_dir + f'{name}_spinup_cyclic-reactive-{case}.xml'\n",
    "#     config[f'transient_{name}_filename'] = input_dir + f'{name}_transient-reactive-{case}.xml'\n",
    "\n",
    "\n",
    "# subcatchment_labels = ['poly_bottom', 'poly_eastbranch', 'poly_westbranch']\n",
    "\n",
    "config['latitude'] = 41 # in deg\n",
    "config['mean_precip'] = 2.500629987318984e-08 # in m/s\n",
    "latitude = config['latitude']\n",
    "mean_precip = config['mean_precip']\n",
    "\n",
    "start_day = 0\n",
    "end_day = 3650 # in days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1fb46b3-636f-4732-a59f-299b3d24385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_dir + f\"{name}_subcatchment_labels.p\", \"rb\") as f:\n",
    "    subcatchment_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9449dec-0085-4978-8ffd-e9d76c007f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_dir + f\"{name}_sidesets.p\", \"rb\") as f:\n",
    "    ls, ss = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "651af6ab-96b1-4703-93a6-5d762c71a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_dir + f\"{name}_nlcd.p\", \"rb\") as f:\n",
    "    nlcd_labels_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c899dfba-a31c-4f44-be3a-f9368dcdbaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if canopy:\n",
    "    nlcd_indices, nlcd_labels = nlcd_labels_dict.keys(), nlcd_labels_dict.values()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b181ade6-5f10-41f4-83dc-601d2947341f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the basin-averaged, annual-averaged precip rate\n",
    "# precip_total = ats_typ['precipitation rain [m s^-1]'] + ats_typ['precipitation snow [m SWE s^-1]']\n",
    "# mean_precip = precip_total.mean()\n",
    "# mean_precip = 2.500629987318984e-08\n",
    "# logging.info(f'Mean annual precip rate [m s^-1] = {mean_precip}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3295a0e4-ba17-4902-9f8e-ced30b94dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsurface_props = pd.read_csv(config['subsurface_properties_filename'], index_col='ats_id')\n",
    "# subsurface_props.loc[999, 'native_index'] = 999\n",
    "# subsurface_props['native_index'] = subsurface_props['native_index'].astype(float).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c1e988e-3941-4aa6-b034-1ab5af6c9344",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add the subsurface and surface domains\n",
    "#\n",
    "# Note this also adds a \"computational domain\" region to the region list, and a vis spec \n",
    "# for \"domain\"\n",
    "def add_domains(main_list, mesh_filename, surface_region='surface', snow=True, canopy=True):\n",
    "    ats_input_spec.public.add_domain(main_list, \n",
    "                                 domain_name='domain', \n",
    "                                 dimension=3, \n",
    "                                 mesh_type='read mesh file',\n",
    "                                 mesh_args={'file':mesh_filename})\n",
    "    if surface_region:\n",
    "        main_list['mesh']['domain']['build columns from set'] = surface_region    \n",
    "    \n",
    "        # Note this also adds a \"surface domain\" region to the region list and a vis spec for \n",
    "        # \"surface\"\n",
    "        ats_input_spec.public.add_domain(main_list,\n",
    "                                domain_name='surface',\n",
    "                                dimension=2,\n",
    "                                mesh_type='surface',\n",
    "                                mesh_args={'surface sideset name':'surface'})\n",
    "    if snow:\n",
    "        # Add the snow and canopy domains, which are aliases to the surface\n",
    "        ats_input_spec.public.add_domain(main_list,\n",
    "                                domain_name='snow',\n",
    "                                dimension=2,\n",
    "                                mesh_type='aliased',\n",
    "                                mesh_args={'target':'surface'})\n",
    "    if canopy:\n",
    "        ats_input_spec.public.add_domain(main_list,\n",
    "                                domain_name='canopy',\n",
    "                                dimension=2,\n",
    "                                mesh_type='aliased',\n",
    "                                mesh_args={'target':'surface'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48154432-d5c6-4698-b25b-e4bbd988bd73",
   "metadata": {},
   "source": [
    "The mafic potential seems wrong below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d6a4d27-1b99-47f8-812f-051741cce16c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_land_cover(main_list, nlcd_indices, nlcd_labels):\n",
    "    # next write a land-cover section for each NLCD type\n",
    "    for index, nlcd_name in zip(nlcd_indices, nlcd_labels):\n",
    "        # this will load default values instead of pulling from the template\n",
    "        ats_input_spec.public.set_land_cover_default_constants(main_list, nlcd_name)\n",
    "\n",
    "    land_cover_list = main_list['state']['initial conditions']['land cover types']\n",
    "    # update some defaults\n",
    "    # ['Other', 'Deciduous Forest', 'Evergreen Forest', 'Shrub/Scrub']\n",
    "    # note, these are from the CLM Technical Note v4.5\n",
    "    #\n",
    "    # Rooting depth curves from CLM TN 4.5 table 8.3\n",
    "    #\n",
    "    # Note, the mafic potential values are likely pretty bad for the types of van Genuchten \n",
    "    # curves we are using (ETC -- add paper citation about this topic).  Likely they need\n",
    "    # to be modified.  Note that these values are in [mm] from CLM TN 4.5 table 8.1, so the \n",
    "    # factor of 10 converts to [Pa]\n",
    "    #\n",
    "    # Note, albedo of canopy taken from CLM TN 4.5 table 3.1\n",
    "    \n",
    "    land_cover_list['Other']['rooting profile alpha [-]'] = 7.0\n",
    "    land_cover_list['Other']['rooting profile beta [-]'] = 2.0\n",
    "    land_cover_list['Other']['rooting depth max [m]'] = 0.5\n",
    "    land_cover_list['Other']['mafic potential at fully closed stomata [Pa]'] = 2750000\n",
    "    land_cover_list['Other']['mafic potential at fully open stomata [Pa]'] = 7400\n",
    "    land_cover_list['Other']['Priestley-Taylor alpha of snow [-]'] = 1.2\n",
    "    land_cover_list['Other']['Priestley-Taylor alpha of bare ground [-]'] = 1.0\n",
    "    land_cover_list['Other']['Priestley-Taylor alpha of canopy [-]'] = 1.2\n",
    "    land_cover_list['Other']['Priestley-Taylor alpha of transpiration [-]'] = 1.2\n",
    "    \n",
    "    land_cover_list['Evergreen Forest']['rooting profile alpha [-]'] = 7.0\n",
    "    land_cover_list['Evergreen Forest']['rooting profile beta [-]'] = 2.0\n",
    "    land_cover_list['Evergreen Forest']['rooting depth max [m]'] = 2.0\n",
    "    land_cover_list['Evergreen Forest']['mafic potential at fully closed stomata [Pa]'] = 2500785\n",
    "    land_cover_list['Evergreen Forest']['mafic potential at fully open stomata [Pa]'] = 647262\n",
    "    land_cover_list['Evergreen Forest']['Priestley-Taylor alpha of snow [-]'] = 1.2\n",
    "    land_cover_list['Evergreen Forest']['Priestley-Taylor alpha of bare ground [-]'] = 1.0\n",
    "    land_cover_list['Evergreen Forest']['Priestley-Taylor alpha of canopy [-]'] = 1.2\n",
    "    land_cover_list['Evergreen Forest']['Priestley-Taylor alpha of transpiration [-]'] = 1.2\n",
    "\n",
    "    land_cover_list['Deciduous Forest']['rooting profile alpha [-]'] = 6.0\n",
    "    land_cover_list['Deciduous Forest']['rooting profile beta [-]'] = 2.0\n",
    "    land_cover_list['Deciduous Forest']['rooting depth max [m]'] = 2.0\n",
    "    land_cover_list['Deciduous Forest']['mafic potential at fully closed stomata [Pa]'] = 2196768\n",
    "    land_cover_list['Deciduous Forest']['mafic potential at fully open stomata [Pa]'] = 343245\n",
    "    land_cover_list['Deciduous Forest']['Priestley-Taylor alpha of snow [-]'] = 1.2\n",
    "    land_cover_list['Deciduous Forest']['Priestley-Taylor alpha of bare ground [-]'] = 1.0\n",
    "    land_cover_list['Deciduous Forest']['Priestley-Taylor alpha of canopy [-]'] = 1.2\n",
    "    land_cover_list['Deciduous Forest']['Priestley-Taylor alpha of transpiration [-]'] = 1.2\n",
    "    \n",
    "    land_cover_list['Shrub/Scrub']['rooting profile alpha [-]'] = 7.0\n",
    "    land_cover_list['Shrub/Scrub']['rooting profile beta [-]'] = 1.5\n",
    "    land_cover_list['Shrub/Scrub']['rooting depth max [m]'] = 0.5\n",
    "    land_cover_list['Shrub/Scrub']['mafic potential at fully closed stomata [Pa]'] = 4197396\n",
    "    land_cover_list['Shrub/Scrub']['mafic potential at fully open stomata [Pa]'] = 813981\n",
    "    land_cover_list['Shrub/Scrub']['Priestley-Taylor alpha of snow [-]'] = 1.2\n",
    "    land_cover_list['Shrub/Scrub']['Priestley-Taylor alpha of bare ground [-]'] = 1.0\n",
    "    land_cover_list['Shrub/Scrub']['Priestley-Taylor alpha of canopy [-]'] = 1.2\n",
    "    land_cover_list['Shrub/Scrub']['Priestley-Taylor alpha of transpiration [-]'] = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ab90f2c-9680-4a45-a014-b7e17e004d24",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add soil sets: note we need a way to name the set, so we use, e.g. SSURGO-MUKEY.\n",
    "def soil_set_name(ats_id):\n",
    "    if ats_id == 999:\n",
    "        return 'bedrock'\n",
    "    source = subsurface_props.loc[ats_id]['source']\n",
    "    native_id = subsurface_props.loc[ats_id]['native_index']\n",
    "    if type(native_id) in [tuple,list]:\n",
    "        native_id = native_id[0]\n",
    "    elif type(native_id) is str:\n",
    "        native_id = native_id.replace('(', '').replace(')', '').split(',')[0]\n",
    "    else:\n",
    "        raise(\"native_id is not a known type!\")\n",
    "    return f\"{source}-{native_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5554c86-22e8-4aee-9889-e2eecd34635d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get an ATS \"main\" input spec list -- note, this is a dummy and is not used to write any files yet\n",
    "def get_main(mesh_filename, subsurface_props, subcatchment_labels=None, snow=True, canopy=True):\n",
    "    main_list = ats_input_spec.public.get_main()\n",
    "    \n",
    "    # get PKs\n",
    "    flow_pk = ats_input_spec.public.add_leaf_pk(main_list, 'flow', main_list['cycle driver']['PK tree'], \n",
    "                                            'richards-spec')\n",
    "\n",
    "    # add the mesh and all domains\n",
    "    # mesh_filename = os.path.join('..', config['mesh_filename'])\n",
    "    add_domains(main_list, mesh_filename, canopy=canopy)\n",
    "    \n",
    "    if canopy:\n",
    "        # add labeled sets\n",
    "        try:\n",
    "            for i in ls:\n",
    "                ats_input_spec.public.add_region_labeled_set(main_list, i.name, i.setid, mesh_filename, i.entity)\n",
    "            for j in ss:\n",
    "                ats_input_spec.public.add_region_labeled_set(main_list, j.name, j.setid, mesh_filename, 'FACE')\n",
    "        except:\n",
    "            logging.info(\"no sidesets provided. adding surface and bottom only\")\n",
    "            for iname,id in zip(['surface','bottom'], [2,1]):\n",
    "                ats_input_spec.public.add_region_labeled_set(main_list, iname, id, mesh_filename, 'FACE') \n",
    "           \n",
    "        # add land cover\n",
    "        add_land_cover(main_list, nlcd_indices, nlcd_labels)\n",
    "    else:\n",
    "        for iname,id in zip(['surface','bottom'], [2,1]):\n",
    "            ats_input_spec.public.add_region_labeled_set(main_list, iname, id, mesh_filename, 'FACE')\n",
    "\n",
    "    # add soil material ID regions, porosity, permeability, and WRMs\n",
    "    for ats_id in subsurface_props.index:\n",
    "        props = subsurface_props.loc[ats_id]\n",
    "        set_name = soil_set_name(ats_id)\n",
    "        \n",
    "        if props['van Genuchten n [-]'] < 1.5:\n",
    "            smoothing_interval = 0.01\n",
    "        else:\n",
    "            smoothing_interval = 0.0\n",
    "        \n",
    "        ats_input_spec.public.add_soil_type(main_list, set_name, ats_id, mesh_filename,\n",
    "                                            float(props['porosity [-]']),\n",
    "                                            float(props['permeability [m^2]']), \n",
    "                                            1.e-9, # pore compressibility, maybe too large?\n",
    "                                            float(props['van Genuchten alpha [Pa^-1]']),\n",
    "                                            float(props['van Genuchten n [-]']),\n",
    "                                            float(props['residual saturation [-]']),\n",
    "                                            float(smoothing_interval))\n",
    "        \n",
    "    # add observations for each subcatchment for transient runs\n",
    "    # this will add default observed variables instead of getting those from template\n",
    "    \n",
    "    obs = ats_input_spec.public.add_observations_water_balance(main_list, region=\"computational domain\", \n",
    "                                                               surface_region= \"surface domain\")\n",
    "    \n",
    "    # add a few additional observations\n",
    "    # make sure to use \"external sides\" as region for calculating net gw flux!\n",
    "    \n",
    "    ats_input_spec.public.add_observeable(obs, 'SWE [m]', 'snow-water_equivalent', \n",
    "                                          'surface domain', 'average','cell', time_integrated=False)\n",
    "    ats_input_spec.public.add_observeable(obs, 'max ponded depth [m]', 'surface-ponded_depth', \n",
    "                                          'surface domain', 'maximum','cell', time_integrated=False)\n",
    "    ats_input_spec.public.add_observeable(obs, 'water to surface [m d^-1]', 'canopy-throughfall_drainage_rain', \n",
    "                                          'surface domain', 'average','cell', time_integrated=True)\n",
    "    ats_input_spec.public.add_observeable(obs, 'snow to surface [m SWE d^-1]', 'canopy-throughfall_drainage_snow', \n",
    "                                          'surface domain', 'average','cell', time_integrated=True)\n",
    "    ats_input_spec.public.add_observeable(obs, 'canopy drainage [m d^-1]', 'canopy-drainage', \n",
    "                                          'surface domain', 'average','cell', time_integrated=True)\n",
    "    ats_input_spec.public.add_observeable(obs, 'total evapotranspiration [m d^-1]', 'surface-total_evapotranspiration', \n",
    "                                          'surface domain', 'average','cell', time_integrated=True)    \n",
    "    \n",
    "    if subcatchment_labels is not None:\n",
    "        for region in subcatchment_labels:\n",
    "            obs = ats_input_spec.public.add_observations_water_balance(main_list, region, \n",
    "                                                                 outlet_region = region + ' outlet')\n",
    "            # add a few additional observations\n",
    "            ats_input_spec.public.add_observeable(obs, 'SWE [m]', 'snow-water_equivalent', \n",
    "                                                  region + ' surface', 'average','cell', time_integrated=False)\n",
    "            ats_input_spec.public.add_observeable(obs, 'max ponded depth [m]', 'surface-ponded_depth', \n",
    "                                                  region + ' surface', 'maximum','cell', time_integrated=False)\n",
    "            ats_input_spec.public.add_observeable(obs, 'water to surface [m d^-1]', 'canopy-throughfall_drainage_rain', \n",
    "                                                  region + ' surface', 'average','cell', time_integrated=True)\n",
    "            ats_input_spec.public.add_observeable(obs, 'snow to surface [m SWE d^-1]', 'canopy-throughfall_drainage_snow', \n",
    "                                                  region + ' surface', 'average','cell', time_integrated=True)\n",
    "            ats_input_spec.public.add_observeable(obs, 'canopy drainage [m d^-1]', 'canopy-drainage', \n",
    "                                                  region + ' surface', 'average','cell', time_integrated=True)\n",
    "            ats_input_spec.public.add_observeable(obs, 'total evapotranspiration [m d^-1]', 'surface-total_evapotranspiration', \n",
    "                                                  region + ' surface', 'average','cell', time_integrated=True)            \n",
    "        \n",
    "    \n",
    "    \n",
    "    return main_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7441c06-f571-4a9d-9179-4f0b262ba359",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def populate_basic_properties(xml, main_xml, canopy=True, homogeneous_wrm=False, homogeneous_poro=False, homogeneous_perm=False):\n",
    "    \"\"\"This function updates an xml object with the above properties for mesh, regions, soil props, and lc props\"\"\"\n",
    "    # find and replace the mesh list\n",
    "    mesh_i = next(i for (i,el) in enumerate(xml) if el.get('name') == 'mesh')\n",
    "    xml[mesh_i] = asearch.child_by_name(main_xml, 'mesh')\n",
    "\n",
    "    # find and replace the regions list\n",
    "    region_i = next(i for (i,el) in enumerate(xml) if el.get('name') == 'regions')\n",
    "    xml[region_i] = asearch.child_by_name(main_xml, 'regions')\n",
    "\n",
    "    # find and replace the WRMs list -- note here we only replace the inner \"WRM parameters\" because the\n",
    "    # demo has this in the PK, not in the field evaluators list\n",
    "    if not homogeneous_wrm:\n",
    "        wrm_list = asearch.find_path(xml, ['PKs', 'water retention evaluator'])\n",
    "        wrm_i = next(i for (i,el) in enumerate(wrm_list) if el.get('name') == 'WRM parameters')\n",
    "        wrm_list[wrm_i] = asearch.find_path(main_xml, ['PKs','water retention evaluator','WRM parameters'])\n",
    "\n",
    "    fe_list = asearch.find_path(xml, ['state', 'field evaluators'])\n",
    "\n",
    "    # find and replace porosity, permeability\n",
    "    if not homogeneous_poro:\n",
    "        poro_i = next(i for (i,el) in enumerate(fe_list) if el.get('name') == 'base_porosity')\n",
    "        fe_list[poro_i] = asearch.find_path(main_xml, ['state', 'field evaluators', 'base_porosity'])\n",
    "\n",
    "    if not homogeneous_perm:\n",
    "        perm_i = next(i for (i,el) in enumerate(fe_list) if el.get('name') == 'permeability')\n",
    "        fe_list[perm_i] = asearch.find_path(main_xml, ['state', 'field evaluators', 'permeability'])\n",
    "\n",
    "    if canopy:\n",
    "        # find and replace land cover\n",
    "        consts_list = asearch.find_path(xml, ['state', 'initial conditions'])\n",
    "        try:\n",
    "            lc_i = next(i for (i,el) in enumerate(consts_list) if el.get('name') == 'land cover types')\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        else:\n",
    "            consts_list[lc_i] = asearch.find_path(main_xml, ['state', 'initial conditions', 'land cover types'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c5613a6-3228-49e5-b089-dcc5754a5dfd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_unique_name(name, homogeneous_wrm=False, homogeneous_poro=False, homogeneous_perm=False):\n",
    "    suffix = '_h'\n",
    "    if homogeneous_perm:\n",
    "        suffix += 'K'\n",
    "    if homogeneous_poro:\n",
    "        suffix += 'p'\n",
    "    if homogeneous_wrm:\n",
    "        suffix += 'w'\n",
    "    if suffix == '_h':\n",
    "        suffix = ''\n",
    "    return name + suffix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "812a7085-c8d3-4b92-8daa-cc11925c3126",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_spinup_steadystate(name, template_file, **kwargs):\n",
    "    name = create_unique_name(name, **kwargs)\n",
    "    filename = config[f'spinup_steadystate_{name}_filename']\n",
    "    logging.info(f'Writing spinup steadystate: {filename}')\n",
    "    \n",
    "    # write the spinup xml file\n",
    "    # load the template file\n",
    "    # xml = aio.fromFile(template_dir + 'spinup_steadystate-template.xml')\n",
    "    xml = aio.fromFile(template_file)\n",
    "    # populate basic properties for mesh, regions, and soil properties\n",
    "    populate_basic_properties(xml, main_xml, **kwargs)\n",
    "\n",
    "    # set the mean avg source as 60% of mean precip\n",
    "    precip_el = asearch.find_path(xml, ['state', 'field evaluators', 'surface-precipitation', \n",
    "                                        'function-constant', 'value'])\n",
    "    precip_el.setValue(mean_precip * .6)\n",
    "\n",
    "    # # update mismatch outlet region\n",
    "    # par = asearch.find_path(xml, ['regions', 'poly_bottom surface outlet', 'label'])\n",
    "    # par.setValue('10012')\n",
    "    # par = asearch.find_path(xml, ['regions', 'surface domain outlet', 'label'])\n",
    "    # par.setValue('10012')\n",
    "    # par = asearch.find_path(xml, ['regions', 'poly_westbranch surface outlet', 'label'])\n",
    "    # par.setValue('10010')     \n",
    "    \n",
    "    # write to disk\n",
    "    # config[f'spinup_steadystate_{name}_filename'] = model_dir + f'input_xml/spinup_steadystate.xml'\n",
    "    aio.toFile(xml, config[f'spinup_steadystate_{name}_filename'])\n",
    "\n",
    "    # make a run directory\n",
    "    # config[f'spinup_steadystate_{name}_rundir'] = f'../model/{name}_spinup_steadystate'\n",
    "    # try:\n",
    "    #     os.mkdir(config[f'spinup_steadystate_{name}_rundir'])\n",
    "    # except FileExistsError:\n",
    "    #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8f94814-fb76-481e-982e-36aef55ced60",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_transient(name, template_filename, canopy=True, cyclic_steadystate=False, start_year=1980, \n",
    "                    end_year=2020, start_day=None, end_day=None, **kwargs):\n",
    "    # make a unique name based on options\n",
    "    name = create_unique_name(name, **kwargs)\n",
    "    \n",
    "\n",
    "    if cyclic_steadystate:\n",
    "        prefix = 'spinup_cyclic'\n",
    "        start_year = 1980\n",
    "        end_year = 1990\n",
    "        previous = 'spinup_steadystate'\n",
    "        runnum = 'run1'     \n",
    "    else:\n",
    "        prefix = 'transient'\n",
    "        previous = 'spinup_cyclic'\n",
    "        runnum = 'run2'\n",
    "        \n",
    "    filename = config[f'{prefix}_{name}_filename']\n",
    "    logging.info(f'Writing {prefix}: {filename}')\n",
    "    # template_filename = template_dir + f'{prefix}-template.xml'\n",
    "    \n",
    "    # load the template file\n",
    "    xml = aio.fromFile(template_filename)\n",
    "\n",
    "    # populate basic properties for mesh, regions, and soil properties\n",
    "    populate_basic_properties(xml, main_xml, canopy=False, **kwargs)\n",
    "\n",
    "    # update the DayMet filenames\n",
    "    # wind speed uses default?\n",
    "    if cyclic_steadystate:\n",
    "        daymet_filename = config['daymet_spinup_filename']\n",
    "    else:\n",
    "        daymet_filename = config['daymet_filename']\n",
    "        \n",
    "    for var in ['surface-incoming_shortwave_radiation',\n",
    "                'surface-precipitation_rain',\n",
    "                'snow-precipitation',\n",
    "                'surface-air_temperature',\n",
    "                'surface-relative_humidity',\n",
    "                'surface-temperature',\n",
    "                'canopy-temperature']:\n",
    "        try:\n",
    "            par = asearch.find_path(xml, ['state', 'field evaluators', var, 'file'])\n",
    "        except aerrors.MissingXMLError:\n",
    "            pass\n",
    "        else:\n",
    "            par.setValue(os.path.join('../..', daymet_filename))\n",
    "    \n",
    "    if canopy:\n",
    "    # update the LAI filenames\n",
    "        for par in asearch.findall_path(xml, ['canopy-leaf_area_index', 'file']):\n",
    "            par.setValue(os.path.join('../..', config['modis_typical_filename']))\n",
    "    \n",
    "    # update the start and end time -- start at Oct 1 of year 0, end 10 years later\n",
    "    if start_day is None:\n",
    "        start_day = 274 + 365*(start_year - 1980)\n",
    "    par = asearch.find_path(xml, ['cycle driver', 'start time'])\n",
    "    par.setValue(start_day)\n",
    "\n",
    "    if end_day is None:\n",
    "        end_day = 274 + 365*(end_year - 1980)\n",
    "    par = asearch.find_path(xml, ['cycle driver', 'end time'])\n",
    "    par.setValue(end_day)\n",
    "    \n",
    "    # update the restart filenames\n",
    "    for var in asearch.findall_path(xml, ['initial condition', 'restart file']):\n",
    "        var.setValue(os.path.join('..', config[f'{previous}_{name}_rundir'], 'checkpoint_final.h5'))\n",
    "\n",
    "    # update the observations list\n",
    "    obs = next(i for (i,el) in enumerate(xml) if el.get('name') == 'observations')\n",
    "    xml[obs] = asearch.child_by_name(main_xml, 'observations')\n",
    "   \n",
    "    # update surface-incident-shortwave-radiation\n",
    "    par = asearch.find_path(xml, ['state', 'field evaluators', 'surface-incident_shortwave_radiation', 'latitude [degrees]'])\n",
    "    par.setValue(latitude)   \n",
    "    \n",
    "    # write to disk and make a directory for running the run\n",
    "    filename = config[f'{prefix}_{name}_filename']\n",
    "    # rundir = config[f'{prefix}_{name}_rundir']\n",
    "\n",
    "    aio.toFile(xml, filename)\n",
    "    # try:\n",
    "    #     os.mkdir(rundir)\n",
    "    # except FileExistsError:\n",
    "    #     pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f52e40-1661-4890-a254-0434c5d239ee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "For the first file, we load a spinup template and write the needed quantities into that file, saving it to the appropriate run directory.  Note there is no DayMet or land cover or LAI properties needed for this run.  The only property that is needed is the domain-averaged, mean annual rainfall rate.  We then take off some for ET (note too wet spins up faster than too dry, so don't take off too much...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880750c7-1531-4759-a39e-3a29e4636055",
   "metadata": {},
   "source": [
    "Create a dummy xml file with the content that template file can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9de8f84a-5f5a-4ee0-ac91-7305106536fd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/ats/ats_input_spec/ats_input_spec/io.py:43: UserWarning: Creating an incomplete XML object, missing entries!\n",
      "  warnings.warn('Creating an incomplete XML object, missing entries!')\n"
     ]
    }
   ],
   "source": [
    "# create the main list, this file is used for filling the template file\n",
    "main_list = get_main(mesh_filename, subsurface_props, subcatchment_labels=subcatchment_labels, canopy=canopy)\n",
    "ats_input_spec.io.write(main_list, config['generated_ats'])\n",
    "main_xml = ats_input_spec.io.to_xml(main_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d30be1-a892-4a65-acaf-b046d78cd64a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "For the second file, we load a transient run template.  This file needs the basics, plus DayMet and LAI as the \"typical year data\".  Also we set the run directory that will be used for the steadystate run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439498d1-cc7c-419e-be60-a17bc4120d4a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "For the third file, we load a transient run template as well.  This file needs the basics, DayMet with the actual data, and we choose for this run to use the MODIS typical year.  MODIS is only available for 2002 on, so if we didn't need 1980-2002 we could use the real data, but for this run we want a longer record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2310158-2fb4-4edf-898c-55caa32430f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 22:06:19,838 - root - INFO: Writing spinup steadystate: ../model/inputs/NeversinkHeadwaters_11Catchments_cluster_spinup_steadystate.xml\n",
      "2022-05-26 22:06:19,877 - root - INFO: Writing spinup_cyclic: ../model/inputs/NeversinkHeadwaters_11Catchments_cluster_spinup_cyclic.xml\n",
      "2022-05-26 22:06:19,959 - root - INFO: Writing transient: ../model/inputs/NeversinkHeadwaters_11Catchments_cluster_transient.xml\n"
     ]
    }
   ],
   "source": [
    "# create the fully-heterogeneous runs\n",
    "# if include_heterogeneous:\n",
    "write_spinup_steadystate(name, config[f'spinup_steadystate_{name}_template'])\n",
    "# make sure the cyclic ends near Oct. 1\n",
    "write_transient(name,  config[f'spinup_cyclic_{name}_template'], canopy=canopy, \n",
    "                cyclic_steadystate=True, \n",
    "                # start_day=start_day, end_day=end_day,\n",
    "                end_year=1990\n",
    "               )\n",
    "write_transient(name, config[f'transient_{name}_template'], canopy=canopy, \n",
    "                cyclic_steadystate=False, start_day=None, end_day=None)\n",
    "\n",
    "# # create homogeneous runs\n",
    "# if include_homogeneous:\n",
    "#     write_spinup_steadystate(name, homogeneous_wrm=True, homogeneous_poro=True, homogeneous_perm=True)\n",
    "#     write_transient(name, True, homogeneous_wrm=True, homogeneous_poro=True, homogeneous_perm=True)\n",
    "#     write_transient(name, False, homogeneous_wrm=True, homogeneous_poro=True, homogeneous_perm=True)\n",
    "    \n",
    "# if include_homogeneous_wrm:\n",
    "#     write_spinup_steadystate(name, homogeneous_wrm=True, homogeneous_poro=False, homogeneous_perm=False)\n",
    "#     write_transient(name, True, homogeneous_wrm=True, homogeneous_poro=False, homogeneous_perm=False)\n",
    "#     write_transient(name, False, homogeneous_wrm=True, homogeneous_poro=False, homogeneous_perm=False)\n",
    "    \n",
    "# if include_homogeneous_wrm_porosity:\n",
    "#     write_spinup_steadystate(name, homogeneous_wrm=True, homogeneous_poro=True, homogeneous_perm=False)\n",
    "#     write_transient(name, True, homogeneous_wrm=True, homogeneous_poro=True, homogeneous_perm=False)\n",
    "#     write_transient(name, False, homogeneous_wrm=True, homogeneous_poro=True, homogeneous_perm=False)\n",
    "    \n",
    "# if include_homogeneous_wrm_permeability:\n",
    "#     write_spinup_steadystate(name, homogeneous_wrm=True, homogeneous_poro=False, homogeneous_perm=True)\n",
    "#     write_transient(name, True, homogeneous_wrm=True, homogeneous_poro=False, homogeneous_perm=True)\n",
    "#     write_transient(name, False, homogeneous_wrm=True, homogeneous_poro=False, homogeneous_perm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a20a9cb7-53ab-4410-bca7-d71a923ee57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_dir + f\"{name}_config.yaml\", 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68b9a6ac-abdb-480a-8cd3-7c783aa44e0b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 22:06:41,283 - root - INFO: this workflow is a total success\n"
     ]
    }
   ],
   "source": [
    "logging.info('this workflow is a total success')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23235d78-18cc-4c81-ad12-c1b5f04cdbcc",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Changes needed to update the xml file:\n",
    "\n",
    "- change `mass_flux` to `water_flux` to work with the master branch\n",
    "- change `net groundwater flux` applied boundary from `\"computational domain boundary\"` to `\"external_sides\"` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1089a80-f9e6-428c-8f43-21feac608d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (watershed_workflow)",
   "language": "python",
   "name": "watershed_workflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
