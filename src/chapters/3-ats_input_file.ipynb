{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3059ae87-5f5c-409c-b216-167261f1dca1",
   "metadata": {},
   "source": [
    "# Write ATS input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee695604-3f49-44a7-abcf-a5486382dd50",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We now generate three input files -- two for spinup (steadystate solution and cyclic steadystate solution) and one for transient runs.\n",
    "\n",
    "* Input files: ATS xml files\n",
    "  - `{WATERSHED_NAME}_spinup-steadystate.xml` the steady-state solution based on uniform application of mean rainfall rate\n",
    "  - `{WATERSHED_NAME}_spinup-cyclic_steadystate.xml` the cyclic steady state based on typical years\n",
    "  - `{WATERSHED_NAME}_transient.xml` the forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06330b40-3a79-46ee-9e9e-2e497062831e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33fe8dfc-db29-4ad2-a579-307ef284f4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, yaml, pickle, datetime\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s: %(message)s')\n",
    "\n",
    "# ats_input_spec library, to be moved to amanzi_xml\n",
    "import ats_input_spec\n",
    "import ats_input_spec.public\n",
    "import ats_input_spec.io\n",
    "\n",
    "# amanzi_xml, included in AMANZI_SRC_DIR/tools/amanzi_xml\n",
    "import amanzi_xml.utils.io as aio\n",
    "import amanzi_xml.utils.search as asearch\n",
    "import amanzi_xml.utils.errors as aerrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ccaf4ce-aea4-4c76-8ada-dad467aac24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = 'CoalCreek' # name the domain, used in filenames, etc\n",
    "config_fname = '../../data/examples/CoalCreek/processed/config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c90b4-51ed-4f95-be22-2cf691f5c0b7",
   "metadata": {},
   "source": [
    "## load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f29672-1958-4e86-a802-b782516b24bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary from the file\n",
    "with open(config_fname, 'r') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f20bd3-022a-4054-b21b-9cfcd1988f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config['spinup_steadystate_rundir'] = os.path.join('..', '..', 'model', '1-spinup_steadystate')\n",
    "config['spinup_cyclic_rundir'] = os.path.join('..', '..', 'model', '2-spinup_cyclic')\n",
    "config['transient_rundir'] = os.path.join('..', '..', 'model', '3-transient')\n",
    "\n",
    "config['spinup_steadystate_template'] = os.path.join('..', '..', 'model', 'inputs', 'spinup_steadystate-template.xml')\n",
    "config['spinup_cyclic_template'] = os.path.join('..', '..', 'model', 'inputs', 'spinup_cyclic-template.xml')\n",
    "config['transient_template'] = os.path.join('..', '..', 'model', 'inputs', 'transient-template.xml')\n",
    "\n",
    "config['watershed_specific_xml'] = os.path.join('..', '..', 'model', 'inputs', f'{name}_specific.xml')\n",
    "config['spinup_steadystate_xml'] = os.path.join('..', '..', 'model', 'inputs', f'{name}_spinup_steadystate.xml')\n",
    "config['spinup_cyclic_xml'] = os.path.join('..', '..', 'model', 'inputs', f'{name}_spinup_cyclic.xml')\n",
    "config['transient_xml'] = os.path.join('..', '..', 'model', 'inputs', f'{name}_transient.xml')\n",
    "\n",
    "latitude = 39 # in degree\n",
    "config['latitude [deg]'] = latitude # latitude of watershed in degree, used to determine incident radiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476cb4a6-df88-4071-b105-f8f50c30c311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config['mesh_filename'] = os.path.join('..', '..', 'data', 'examples','CoalCreek', 'processed','watershed_mesh.exo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cef6df82-094c-44f8-876d-78f7c05b0f20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LAI_filename': '../../data/examples/CoalCreek/processed/watershed_lai_raw.h5',\n",
       " 'LAI_typical_filename': '../../data/examples/CoalCreek/processed/watershed_lai_typical.h5',\n",
       " 'catchment_labels': ['140200010204'],\n",
       " 'daymet_filename': '../../data/examples/CoalCreek/processed/watershed_daymet_raw.h5',\n",
       " 'daymet_typical_filename': '../../data/examples/CoalCreek/processed/watershed_daymet_typical.h5',\n",
       " 'end_date': '2016-10-1',\n",
       " 'generated_ats': '../../model/inputs/CoalCreek_generated_ats.xml',\n",
       " 'labeled_sets': {'140200010204': {'entity': 'CELL', 'setid': 10000}},\n",
       " 'latitude [deg]': 39,\n",
       " 'mean_precip [m s^-1]': 2.1640812896024845e-08,\n",
       " 'mesh_filename': '../../data/examples/CoalCreek/processed/watershed_mesh.exo',\n",
       " 'nlcd_indices': [8, 9, 10],\n",
       " 'nlcd_labels': ['MODIS Woody Savannas', 'MODIS Savannas', 'MODIS Grasslands'],\n",
       " 'origin_date': '1980-1-1',\n",
       " 'side_sets': {'140200010204 boundary': {'setid': 10002},\n",
       "  '140200010204 outlet': {'setid': 10003},\n",
       "  '140200010204 surface': {'setid': 10001},\n",
       "  'MODIS Grasslands': {'setid': 10},\n",
       "  'MODIS Savannas': {'setid': 9},\n",
       "  'MODIS Woody Savannas': {'setid': 8},\n",
       "  'bottom': {'setid': 1},\n",
       "  'external_sides': {'setid': 3},\n",
       "  'surface': {'setid': 2}},\n",
       " 'spinup_cyclic_rundir': '../../model/2-spinup_cyclic',\n",
       " 'spinup_cyclic_template': '../../model/inputs/spinup_cyclic-template.xml',\n",
       " 'spinup_cyclic_xml': '../../model/inputs/CoalCreek_spinup_cyclic.xml',\n",
       " 'spinup_steadystate_rundir': '../../model/1-spinup_steadystate',\n",
       " 'spinup_steadystate_template': '../../model/inputs/spinup_steadystate-template.xml',\n",
       " 'spinup_steadystate_xml': '../../model/inputs/CoalCreek_spinup_steadystate.xml',\n",
       " 'start_date': '2015-10-1',\n",
       " 'subsurface_properties_filename': '../../data/examples/CoalCreek/processed/watershed_subsurface_properties.csv',\n",
       " 'transient_rundir': '../../model/3-transient',\n",
       " 'transient_template': '../../model/inputs/transient-template.xml',\n",
       " 'transient_xml': '../../model/inputs/CoalCreek_transient.xml',\n",
       " 'watershed_specific_xml': '../../model/inputs/CoalCreek_specific.xml'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27ab071-360b-4f38-be30-67ea9b400257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nlcd_indices = config['nlcd_indices']\n",
    "nlcd_labels = config['nlcd_labels']\n",
    "subcatchment_labels = config['catchment_labels']\n",
    "ls = config['labeled_sets']\n",
    "ss = config['side_sets']\n",
    "mean_precip = config['mean_precip [m s^-1]']\n",
    "start_date = config['start_date']\n",
    "end_date = config['end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3295a0e4-ba17-4902-9f8e-ced30b94dbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load subsurface properties\n",
    "subsurface_props = pd.read_csv(config['subsurface_properties_filename'], index_col='ats_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682ff441-64ae-4388-8b20-83b9685850d2",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1e988e-3941-4aa6-b034-1ab5af6c9344",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_domains(main_list, mesh_filename, surface_region='surface'):\n",
    "    \"\"\"add the subsurface and surface domains. Note this also adds \n",
    "    a 'computational domain' region to the region list, and a vis spec for domain.\"\"\"\n",
    "    # add subsurface domain\n",
    "    ats_input_spec.public.add_domain(main_list, \n",
    "                                 domain_name='domain', \n",
    "                                 dimension=3, \n",
    "                                 mesh_type='read mesh file',\n",
    "                                 mesh_args={'file':mesh_filename})\n",
    "    \n",
    "    # if surface_region:\n",
    "    main_list['mesh']['domain']['build columns from set'] = surface_region    \n",
    "\n",
    "    # Note this also adds a \"surface domain\" region to the region list and a vis spec for \n",
    "    # \"surface\"\n",
    "    ats_input_spec.public.add_domain(main_list,\n",
    "                            domain_name='surface',\n",
    "                            dimension=2,\n",
    "                            mesh_type='surface',\n",
    "                            mesh_args={'surface sideset name':'surface'})\n",
    "    # if snow:\n",
    "    # Add the snow and canopy domains, which are aliases to the surface\n",
    "    ats_input_spec.public.add_domain(main_list,\n",
    "                            domain_name='snow',\n",
    "                            dimension=2,\n",
    "                            mesh_type='aliased',\n",
    "                            mesh_args={'target':'surface'})\n",
    "    # if canopy:\n",
    "    ats_input_spec.public.add_domain(main_list,\n",
    "                            domain_name='canopy',\n",
    "                            dimension=2,\n",
    "                            mesh_type='aliased',\n",
    "                            mesh_args={'target':'surface'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d6a4d27-1b99-47f8-812f-051741cce16c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_land_cover(main_list, nlcd_labels):\n",
    "    \"\"\"write a land-cover section for each NLCD type\"\"\"\n",
    "    for nlcd_name in nlcd_labels:\n",
    "        # this will load default values instead of pulling from the template\n",
    "        ats_input_spec.public.set_land_cover_default_constants(main_list, nlcd_name)\n",
    "\n",
    "    land_cover_list = main_list['state']['initial conditions']['land cover types']\n",
    "    \n",
    "    # update some defaults\n",
    "\n",
    "    # note, these are from the CLM Technical Note v4.5\n",
    "    #\n",
    "    # Rooting depth curves from CLM TN 4.5 table 8.3\n",
    "    #\n",
    "    # Note, the mafic potential values are likely pretty bad for the types of van Genuchten \n",
    "    # curves we are using (ETC -- add paper citation about this topic).  Likely they need\n",
    "    # to be modified.  Note that these values are in [mm] from CLM TN 4.5 table 8.1, so the \n",
    "    # factor of 10 converts to [Pa]\n",
    "    #\n",
    "    # Note, albedo of canopy taken from CLM TN 4.5 table 3.1\n",
    "    def name_has_string(name, str_list):\n",
    "        return any(s in name for s in str_list)\n",
    "    \n",
    "    for ilc in nlcd_labels:\n",
    "        new_ilc = ilc.lower()\n",
    "        if name_has_string(new_ilc, [\"evergreen\", \"woody savannas\"]):\n",
    "            land_cover_list[ilc]['rooting profile alpha [-]'] = 7.0\n",
    "            land_cover_list[ilc]['rooting profile beta [-]'] = 2.0\n",
    "            land_cover_list[ilc]['rooting depth max [m]'] = 2.0\n",
    "            land_cover_list[ilc]['mafic potential at fully closed stomata [Pa]'] = 2500785\n",
    "            land_cover_list[ilc]['mafic potential at fully open stomata [Pa]'] = 647262  \n",
    "        elif name_has_string(new_ilc, [\"deciduous\", \"savannas\", \"mix\"]):\n",
    "            land_cover_list[ilc]['rooting profile alpha [-]'] = 6.0\n",
    "            land_cover_list[ilc]['rooting profile beta [-]'] = 2.0\n",
    "            land_cover_list[ilc]['rooting depth max [m]'] = 2.0\n",
    "            land_cover_list[ilc]['mafic potential at fully closed stomata [Pa]'] = 2196768\n",
    "            land_cover_list[ilc]['mafic potential at fully open stomata [Pa]'] = 343245\n",
    "        elif name_has_string(new_ilc, [\"shrub\", \"grassland\"]):\n",
    "            land_cover_list[ilc]['rooting profile alpha [-]'] = 7.0\n",
    "            land_cover_list[ilc]['rooting profile beta [-]'] = 1.5\n",
    "            land_cover_list[ilc]['rooting depth max [m]'] = 0.5\n",
    "            land_cover_list[ilc]['mafic potential at fully closed stomata [Pa]'] = 4197396\n",
    "            land_cover_list[ilc]['mafic potential at fully open stomata [Pa]'] = 813981\n",
    "        else:\n",
    "            logging.info(f\"Default values are used for {ilc}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab90f2c-9680-4a45-a014-b7e17e004d24",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soil_set_name(ats_id):\n",
    "    \"\"\"add soil sets: note we need a way to name the set, so we use, e.g. SSURGO-MUKEY.\"\"\"\n",
    "    if ats_id == 999:\n",
    "        return 'bedrock'\n",
    "    source = subsurface_props.loc[ats_id]['source']\n",
    "    native_id = subsurface_props.loc[ats_id]['native_index']\n",
    "    if type(native_id) in [tuple,list]:\n",
    "        native_id = native_id[0]\n",
    "    elif type(native_id) is str:\n",
    "        native_id = native_id.replace('(', '').replace(')', '').split(',')[0]\n",
    "    else:\n",
    "        raise(\"native_id is not a known type!\")\n",
    "    return f\"{source}-{native_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5554c86-22e8-4aee-9889-e2eecd34635d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_main(mesh_filename, subsurface_props, subcatchment_labels=None, snow=True):\n",
    "    \"\"\"\n",
    "    Get an ATS \"main\" input spec list -- note, this is a dummy and is not used to write any files yet\n",
    "\n",
    "    \"\"\"\n",
    "    # get the main input structures including mesh, region, cycle driver, PKs, state, observations, and checkpoint\n",
    "    main_list = ats_input_spec.public.get_main()\n",
    "    \n",
    "    # get PKs\n",
    "    flow_pk = ats_input_spec.public.add_leaf_pk(main_list, 'flow', main_list['cycle driver']['PK tree'], \n",
    "                                            'richards-spec')\n",
    "\n",
    "    # add the mesh and all domains\n",
    "    # mesh_filename = os.path.join('..', config['mesh_filename'])\n",
    "    add_domains(main_list, mesh_filename)\n",
    "    \n",
    "    # add labeled sets and sidesets\n",
    "    try:\n",
    "        for iname,ival in ls.items():\n",
    "            ats_input_spec.public.add_region_labeled_set(main_list, iname, ival['setid'], mesh_filename, ival['entity'])\n",
    "        for iname,ival in ss.items():\n",
    "            ats_input_spec.public.add_region_labeled_set(main_list, iname, ival['setid'], mesh_filename, 'FACE')\n",
    "    except:\n",
    "        logging.info(\"no sidesets provided. adding surface and bottom only\")\n",
    "        for iname,id in zip(['surface','bottom'], [2,1]):\n",
    "            ats_input_spec.public.add_region_labeled_set(main_list, iname, id, mesh_filename, 'FACE') \n",
    "\n",
    "    # add land cover\n",
    "    add_land_cover(main_list, nlcd_labels)\n",
    "\n",
    "    # add LAIs\n",
    "    ats_input_spec.public.add_lai_evaluators(main_list, config['LAI_filename'], nlcd_labels)\n",
    "    \n",
    "    # add soil material ID regions, porosity, permeability, and WRMs\n",
    "    for ats_id in subsurface_props.index:\n",
    "        props = subsurface_props.loc[ats_id]\n",
    "        set_name = soil_set_name(ats_id)\n",
    "        \n",
    "        if props['van Genuchten n [-]'] < 1.5:\n",
    "            smoothing_interval = 0.01\n",
    "        else:\n",
    "            smoothing_interval = 0.0\n",
    "        \n",
    "        ats_input_spec.public.add_soil_type(main_list, set_name, ats_id, mesh_filename,\n",
    "                                            float(props['porosity [-]']),\n",
    "                                            float(props['permeability [m^2]']), \n",
    "                                            1.e-9, # pore compressibility, maybe too large?\n",
    "                                            float(props['van Genuchten alpha [Pa^-1]']),\n",
    "                                            float(props['van Genuchten n [-]']),\n",
    "                                            float(props['residual saturation [-]']),\n",
    "                                            float(smoothing_interval))\n",
    "        \n",
    "    # add observations for each subcatchment for transient runs\n",
    "    # this will add default observed variables instead of getting those from template\n",
    "    \n",
    "    obs = ats_input_spec.public.add_observations_water_balance(main_list, region=\"computational domain\", \n",
    "                                                               surface_region= \"surface domain\")\n",
    "    \n",
    "    if subcatchment_labels is not None:\n",
    "        for region in subcatchment_labels:\n",
    "            obs = ats_input_spec.public.add_observations_water_balance(main_list, region, \n",
    "                                                                 outlet_region = region + ' outlet')\n",
    "    return main_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7441c06-f571-4a9d-9179-4f0b262ba359",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def populate_basic_properties(template_xml, main_xml, homogeneous_wrm=False, homogeneous_poro=False, homogeneous_perm=False):\n",
    "    \"\"\"This function updates an xml object with the above properties for mesh, regions, soil props, and lc props\"\"\"\n",
    "    # find and replace the mesh list\n",
    "    mesh_i = next(i for (i,el) in enumerate(template_xml) if el.get('name') == 'mesh')\n",
    "    template_xml[mesh_i] = asearch.child_by_name(main_xml, 'mesh')\n",
    "\n",
    "    # find and replace the regions list\n",
    "    region_i = next(i for (i,el) in enumerate(template_xml) if el.get('name') == 'regions')\n",
    "    template_xml[region_i] = asearch.child_by_name(main_xml, 'regions')\n",
    "    \n",
    "    # find and replace land cover\n",
    "    consts_list = asearch.find_path(template_xml, ['state', 'initial conditions'])\n",
    "    try:\n",
    "        lc_i = next(i for (i,el) in enumerate(consts_list) if el.get('name') == 'land cover types')\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    else:\n",
    "        consts_list[lc_i] = asearch.find_path(main_xml, ['state', 'initial conditions', 'land cover types'])\n",
    "        \n",
    "    # find and replace the WRMs list -- note here we only replace the inner \"WRM parameters\" because the\n",
    "    # demo has this in the PK, not in the evaluators list\n",
    "    if not homogeneous_wrm:\n",
    "        wrm_list = asearch.find_path(template_xml, ['PKs', 'water retention evaluator'])\n",
    "        wrm_i = next(i for (i,el) in enumerate(wrm_list) if el.get('name') == 'WRM parameters')\n",
    "        wrm_list[wrm_i] = asearch.find_path(main_xml, ['PKs','water retention evaluator','WRM parameters'])\n",
    "\n",
    "    fe_list = asearch.find_path(template_xml, ['state', 'evaluators'])\n",
    "\n",
    "    # update LAIs in the template\n",
    "    # consts_list = asearch.find_path(template_xml, ['state', 'initial conditions'])\n",
    "    try:\n",
    "        lc_i = next(i for (i,el) in enumerate(fe_list) if el.get('name') == 'canopy-leaf_area_index')\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    else:    \n",
    "        fe_list[lc_i] = asearch.find_path(main_xml, ['state', 'evaluators', 'canopy-leaf_area_index'])    \n",
    "    \n",
    "    # find and replace porosity, permeability\n",
    "    if not homogeneous_poro:\n",
    "        poro_i = next(i for (i,el) in enumerate(fe_list) if el.get('name') == 'base_porosity')\n",
    "        fe_list[poro_i] = asearch.find_path(main_xml, ['state', 'evaluators', 'base_porosity'])\n",
    "\n",
    "    if not homogeneous_perm:\n",
    "        perm_i = next(i for (i,el) in enumerate(fe_list) if el.get('name') == 'permeability')\n",
    "        fe_list[perm_i] = asearch.find_path(main_xml, ['state', 'evaluators', 'permeability'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c5613a6-3228-49e5-b089-dcc5754a5dfd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_unique_name(name, homogeneous_wrm=False, homogeneous_poro=False, homogeneous_perm=False):\n",
    "    suffix = '_h'\n",
    "    if homogeneous_perm:\n",
    "        suffix += 'K'\n",
    "    if homogeneous_poro:\n",
    "        suffix += 'p'\n",
    "    if homogeneous_wrm:\n",
    "        suffix += 'w'\n",
    "    if suffix == '_h':\n",
    "        suffix = ''\n",
    "    return name + suffix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "812a7085-c8d3-4b92-8daa-cc11925c3126",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_spinup_steadystate(template_file, **kwargs):\n",
    "    \"\"\" Write the spinup steadystate xml file.\"\"\"\n",
    "    # name = create_unique_name(name, **kwargs)\n",
    "    filename = config[f'spinup_steadystate_xml']\n",
    "    logging.info(f'Writing spinup steadystate: {filename}')\n",
    "    \n",
    "    # load the template file\n",
    "    template_xml = aio.fromFile(template_file)\n",
    "    \n",
    "    # populate basic properties for mesh, regions, and soil properties\n",
    "    populate_basic_properties(template_xml, main_xml, **kwargs)\n",
    "\n",
    "    # set the mean avg source as 60% of mean precip\n",
    "    precip_el = asearch.find_path(template_xml, ['state', 'evaluators', 'surface-precipitation', \n",
    "                                        'function-constant', 'value'])\n",
    "    precip_el.setValue(mean_precip * .6)\n",
    "   \n",
    "    # write to disk\n",
    "    aio.toFile(template_xml, config[f'spinup_steadystate_xml'])\n",
    "\n",
    "    # make a run directory\n",
    "    try:\n",
    "        os.mkdir(config[f'spinup_steadystate_rundir'])\n",
    "    except FileExistsError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8f94814-fb76-481e-982e-36aef55ced60",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_transient(template_filename, start_date, end_date, cyclic_steadystate=False,\n",
    "                    time0 = \"1980-1-1\", **kwargs):\n",
    "    \"\"\"Write transient xml file using template. \n",
    "    \n",
    "    Parameters:\n",
    "        template_filename: str,\n",
    "            Path to the transient template xml.\n",
    "        start_date: str,\n",
    "            Start date of the transient run. Note it defaults to '1980-10-1' for cyclic runs.\n",
    "        end_date: str,\n",
    "            End date of the transient run. Note it defaults to '1990-10-1' for cyclic runs.  \n",
    "        cyclic_steadystate: bool\n",
    "            Generate input xml for cyclic runs if True. Default is False.\n",
    "        time0: str,\n",
    "            Default origin time in the model. This should be consistent with all other input files \n",
    "            including forcing and LAI.\n",
    "            \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    if cyclic_steadystate:\n",
    "        prefix = 'spinup_cyclic'\n",
    "        # start_year = 1980\n",
    "        # end_year = 1990\n",
    "        start_datetime = datetime.datetime.strptime(\"1980-10-1\", '%Y-%m-%d').date()\n",
    "        end_datetime = datetime.datetime.strptime(\"1990-10-1\", '%Y-%m-%d').date()        \n",
    "        previous = 'spinup_steadystate'\n",
    "        # runnum = 'run1'     \n",
    "    else:\n",
    "        prefix = 'transient'\n",
    "        start_datetime = datetime.datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "        end_datetime = datetime.datetime.strptime(end_date, '%Y-%m-%d').date()\n",
    "        previous = 'spinup_cyclic'\n",
    "        # runnum = 'run2'\n",
    "        \n",
    "    filename = config[f'{prefix}_xml']\n",
    "    logging.info(f'Writing {prefix} xml: {filename}')\n",
    "    # template_filename = template_dir + f'{prefix}-template.xml'\n",
    "    \n",
    "    # load the template file\n",
    "    template_xml = aio.fromFile(template_filename)\n",
    "\n",
    "    # populate basic properties for mesh, regions, and soil properties\n",
    "    populate_basic_properties(template_xml, main_xml, **kwargs)\n",
    "\n",
    "    # update the DayMet filenames\n",
    "    # wind speed uses default?\n",
    "    if cyclic_steadystate:\n",
    "        daymet_filename = config['daymet_typical_filename']\n",
    "        LAI_filename = config['LAI_typical_filename']\n",
    "    else:\n",
    "        daymet_filename = config['daymet_filename']\n",
    "        LAI_filename = config['LAI_filename']\n",
    "        \n",
    "    for var in ['surface-incoming_shortwave_radiation',\n",
    "                'surface-precipitation_rain',\n",
    "                'snow-precipitation',\n",
    "                'surface-air_temperature',\n",
    "                'surface-vapor_pressure_air',\n",
    "                'surface-temperature',\n",
    "                ]:\n",
    "        try:\n",
    "            par = asearch.find_path(template_xml, ['state', 'evaluators', var, 'file'])\n",
    "        except aerrors.MissingXMLError:\n",
    "            pass\n",
    "        else:\n",
    "            par.setValue(daymet_filename)\n",
    "    \n",
    "    # update the LAI filenames\n",
    "    for par in asearch.findall_path(template_xml, ['canopy-leaf_area_index', 'file']):\n",
    "        par.setValue(os.path.join(LAI_filename))\n",
    "    \n",
    "    # update the start and end time -- start at Oct 1 of year 0, end 10 years later\n",
    "\n",
    "    origin_datetime = datetime.datetime.strptime(time0, '%Y-%m-%d').date()\n",
    "    start_days = (start_datetime - origin_datetime).total_seconds() // 86400\n",
    "    end_days = (end_datetime - origin_datetime).total_seconds() // 86400\n",
    "    \n",
    "    # if start_day is None:\n",
    "    #     start_day = 274 + 365*(start_year - 1980)\n",
    "    par = asearch.find_path(template_xml, ['cycle driver', 'start time'])\n",
    "    par.setValue(start_days)\n",
    "\n",
    "    # if end_day is None:\n",
    "    #     end_day = 274 + 365*(end_year - 1980)\n",
    "    par = asearch.find_path(template_xml, ['cycle driver', 'end time'])\n",
    "    par.setValue(end_days)\n",
    "    \n",
    "    # update the restart filenames\n",
    "    for var in asearch.findall_path(template_xml, ['initial condition', 'restart file']):\n",
    "        var.setValue(os.path.join('..', config[f'{previous}_rundir'], 'checkpoint_final.h5'))\n",
    "\n",
    "    # update the observations list\n",
    "    obs = next(i for (i,el) in enumerate(template_xml) if el.get('name') == 'observations')\n",
    "    template_xml[obs] = asearch.child_by_name(main_xml, 'observations')\n",
    "   \n",
    "    # update surface-incident-shortwave-radiation\n",
    "    par = asearch.find_path(template_xml, ['state', 'evaluators', 'surface-incident_shortwave_radiation', 'latitude [degrees]'])\n",
    "    par.setValue(latitude)   \n",
    "    \n",
    "    # write to disk and make a directory for running the run\n",
    "    filename = config[f'{prefix}_xml']\n",
    "    aio.toFile(template_xml, filename)\n",
    "    # rundir = config[f'{prefix}_{name}_rundir']\n",
    "\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(config[f'{prefix}_rundir'])\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633717c9-8b2f-44d9-857f-7d0cca9db4e2",
   "metadata": {},
   "source": [
    "## Generate watershed-specific properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880750c7-1531-4759-a39e-3a29e4636055",
   "metadata": {},
   "source": [
    "Create a dummy xml file with watershed specific content (e.g., meshes, domain, forcing, and land covers) that will replace sections within the template files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9de8f84a-5f5a-4ee0-ac91-7305106536fd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuai/github/ats_input_spec/ats_input_spec/io.py:43: UserWarning: Creating an incomplete XML object, missing entries!\n",
      "  warnings.warn('Creating an incomplete XML object, missing entries!')\n"
     ]
    }
   ],
   "source": [
    "# create the main list, this file is used for filling the template file\n",
    "main_list = get_main(mesh_filename = config['mesh_filename'], subsurface_props = subsurface_props, subcatchment_labels=subcatchment_labels)\n",
    "main_xml = ats_input_spec.io.to_xml(main_list)\n",
    "\n",
    "# save generated xml \n",
    "ats_input_spec.io.write(main_list, config['watershed_specific_xml'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99e31b-a02d-4ea4-9493-d96d4c672a70",
   "metadata": {},
   "source": [
    "## Write input files\n",
    "\n",
    "Replace template files with generated watershed specific properties. This also sets the start and end date of the simulations, and creates directories for each run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a35d7-2f69-4c40-8c83-c5e1f726dea4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- `{name}_spinup_steadystate.xml`: For the first file, we load a spinup template and write the needed quantities into that file, saving it to the appropriate run directory.  Note there is no DayMet or land cover or LAI properties needed for this run.  The only property that is needed is the domain-averaged, mean annual rainfall rate.  We then take off some for ET (note too wet spins up faster than too dry, so don't take off too much...).\n",
    "\n",
    "- `{name}_spinup_cyclic.xml`: For the second file, we load a transient run template.  This file needs the basics, plus DayMet and LAI as the \"typical year data\".  Also we set the run directory that will be used for the steadystate run.\n",
    "\n",
    "- `{name}_transient.xml`: For the third file, we load a transient run template as well.  This file needs the basics, DayMet with the actual data, and we choose for this run to use the MODIS typical year.  MODIS is only available for 2002 on, so if we didn't need 1980-2002 we could use the real data, but for this run we want a longer record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2310158-2fb4-4edf-898c-55caa32430f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 13:03:07,416 - root - INFO: Writing spinup steadystate: ../../model/inputs/CoalCreek_spinup_steadystate.xml\n",
      "2023-07-18 13:03:07,423 - root - INFO: Writing spinup_cyclic xml: ../../model/inputs/CoalCreek_spinup_cyclic.xml\n",
      "2023-07-18 13:03:07,438 - root - INFO: Writing transient xml: ../../model/inputs/CoalCreek_transient.xml\n"
     ]
    }
   ],
   "source": [
    "# create a steady-state run\n",
    "write_spinup_steadystate(config[f'spinup_steadystate_template'])\n",
    "\n",
    "# make sure the cyclic ends near Oct. 1\n",
    "write_transient(config[f'spinup_cyclic_template'],  \n",
    "                cyclic_steadystate=True, \n",
    "                start_date = start_date, end_date=end_date,\n",
    "               )\n",
    "\n",
    "# create the fully-heterogeneous runs\n",
    "write_transient(config[f'transient_template'], \n",
    "                cyclic_steadystate=False, \n",
    "                 start_date = start_date, end_date=end_date,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a20a9cb7-53ab-4410-bca7-d71a923ee57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_fname, 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f30974-a723-4fb8-9e77-2478ae840011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watershed_workflow-2023-04-03",
   "language": "python",
   "name": "watershed_workflow-2023-04-03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
